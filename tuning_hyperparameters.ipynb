{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d47efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Meilleur nombre de voisins : {'n_neighbors': 18}\n",
      "KNN - Accuracy : 0.8434904867024072\n",
      "KNN - Recall : 0.8434904867024072\n",
      "KNN - F1 Score : 0.7968368332208058\n",
      "KNN - Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.98      0.91     64180\n",
      "         1.0       0.00      0.00      0.00      1425\n",
      "         2.0       0.48      0.12      0.19     10499\n",
      "\n",
      "    accuracy                           0.84     76104\n",
      "   macro avg       0.45      0.37      0.37     76104\n",
      "weighted avg       0.79      0.84      0.80     76104\n",
      "\n",
      "\n",
      "Decision Tree - Meilleure profondeur : {'max_depth': 6}\n",
      "Decision Tree - Accuracy : 0.8482865552401976\n",
      "Decision Tree - Recall : 0.8482865552401976\n",
      "Decision Tree - F1 Score : 0.8014098321135305\n",
      "Decision Tree - Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.99      0.92     64180\n",
      "         1.0       0.00      0.00      0.00      1425\n",
      "         2.0       0.56      0.12      0.20     10499\n",
      "\n",
      "    accuracy                           0.85     76104\n",
      "   macro avg       0.47      0.37      0.37     76104\n",
      "weighted avg       0.80      0.85      0.80     76104\n",
      "\n",
      "\n",
      "Random Forest - Meilleurs paramètres : {'max_depth': 15, 'n_estimators': 150}\n",
      "Random Forest - Accuracy : 0.8496925260170294\n",
      "Random Forest - Recall : 0.8496925260170294\n",
      "Random Forest - F1 Score : 0.8064938766623447\n",
      "Random Forest - Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.98      0.92     64180\n",
      "         1.0       0.00      0.00      0.00      1425\n",
      "         2.0       0.57      0.15      0.24     10499\n",
      "\n",
      "    accuracy                           0.85     76104\n",
      "   macro avg       0.48      0.38      0.38     76104\n",
      "weighted avg       0.80      0.85      0.81     76104\n",
      "\n",
      "\n",
      "Comparaison des performances des modèles :\n",
      "KNN -> Accuracy: 0.8434904867024072, Recall: 0.8434904867024072, F1 Score: 0.7968368332208058\n",
      "Decision Tree -> Accuracy: 0.8482865552401976, Recall: 0.8482865552401976, F1 Score: 0.8014098321135305\n",
      "Random Forest -> Accuracy: 0.8496925260170294, Recall: 0.8496925260170294, F1 Score: 0.8064938766623447\n",
      "\n",
      "Le modèle avec le meilleur F1-score est : Random Forest avec un F1-score de 0.8064938766623447\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Préparer les données (X pour les caractéristiques, y pour la variable cible)\n",
    "X = df.drop(columns=['Diabetes_012'])\n",
    "y = df['Diabetes_012']\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "### Modèle 1 : K-Nearest Neighbors\n",
    "knn_params = {'n_neighbors': range(1, 20)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = GridSearchCV(knn, knn_params, cv=5, scoring='accuracy')\n",
    "knn_grid.fit(X_train, y_train)\n",
    "best_knn = knn_grid.best_estimator_\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn, average='weighted')\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "\n",
    "print(\"KNN - Meilleur nombre de voisins :\", knn_grid.best_params_)\n",
    "print(\"KNN - Accuracy :\", accuracy_knn)\n",
    "print(\"KNN - Recall :\", recall_knn)\n",
    "print(\"KNN - F1 Score :\", f1_knn)\n",
    "print(\"KNN - Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "### Modèle 2 : Decision Tree\n",
    "tree_params = {'max_depth': range(1, 20)}\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree_grid = GridSearchCV(tree, tree_params, cv=5, scoring='accuracy')\n",
    "tree_grid.fit(X_train, y_train)\n",
    "best_tree = tree_grid.best_estimator_\n",
    "y_pred_tree = best_tree.predict(X_test)\n",
    "\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "recall_tree = recall_score(y_test, y_pred_tree, average='weighted')\n",
    "f1_tree = f1_score(y_test, y_pred_tree, average='weighted')\n",
    "\n",
    "print(\"\\nDecision Tree - Meilleure profondeur :\", tree_grid.best_params_)\n",
    "print(\"Decision Tree - Accuracy :\", accuracy_tree)\n",
    "print(\"Decision Tree - Recall :\", recall_tree)\n",
    "print(\"Decision Tree - F1 Score :\", f1_tree)\n",
    "print(\"Decision Tree - Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "\n",
    "### Modèle 3 : Random Forest\n",
    "rf_params = {'n_estimators': [50, 100, 150], 'max_depth': [5, 10, 15, None]}\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "print(\"\\nRandom Forest - Meilleurs paramètres :\", rf_grid.best_params_)\n",
    "print(\"Random Forest - Accuracy :\", accuracy_rf)\n",
    "print(\"Random Forest - Recall :\", recall_rf)\n",
    "print(\"Random Forest - F1 Score :\", f1_rf)\n",
    "print(\"Random Forest - Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "### Comparaison des modèles\n",
    "print(\"\\nComparaison des performances des modèles :\")\n",
    "print(f\"KNN -> Accuracy: {accuracy_knn}, Recall: {recall_knn}, F1 Score: {f1_knn}\")\n",
    "print(f\"Decision Tree -> Accuracy: {accuracy_tree}, Recall: {recall_tree}, F1 Score: {f1_tree}\")\n",
    "print(f\"Random Forest -> Accuracy: {accuracy_rf}, Recall: {recall_rf}, F1 Score: {f1_rf}\")\n",
    "\n",
    "# Résumer le modèle avec la meilleure performance globale en F1-score\n",
    "best_model = max(\n",
    "    ((f1_knn, \"KNN\"), (f1_tree, \"Decision Tree\"), (f1_rf, \"Random Forest\")),\n",
    "    key=lambda x: x[0]\n",
    ")\n",
    "print(f\"\\nLe modèle avec le meilleur F1-score est : {best_model[1]} avec un F1-score de {best_model[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d7eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
